{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11988915,"sourceType":"datasetVersion","datasetId":7540695}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"GPU available:\", tf.config.list_physical_devices('GPU'))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:39:10.656459Z","iopub.execute_input":"2025-06-05T01:39:10.656630Z","iopub.status.idle":"2025-06-05T01:39:25.513694Z","shell.execute_reply.started":"2025-06-05T01:39:10.656614Z","shell.execute_reply":"2025-06-05T01:39:25.513061Z"}},"outputs":[{"name":"stderr","text":"2025-06-05 01:39:12.057054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749087552.289413      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749087552.354574      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"TensorFlow version: 2.18.0\nGPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -U keras-nlp\n!pip install -U pandas\n!pip install -U clean-text\n!pip install -U tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:39:25.515385Z","iopub.execute_input":"2025-06-05T01:39:25.515818Z","iopub.status.idle":"2025-06-05T01:39:43.211973Z","shell.execute_reply.started":"2025-06-05T01:39:25.515799Z","shell.execute_reply":"2025-06-05T01:39:43.210949Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-nlp in /usr/local/lib/python3.11/dist-packages (0.18.1)\nCollecting keras-nlp\n  Downloading keras_nlp-0.21.1-py3-none-any.whl.metadata (1.2 kB)\nCollecting keras-hub==0.21.1 (from keras-nlp)\n  Downloading keras_hub-0.21.1-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: keras>=3.5 in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.21.1->keras-nlp) (3.8.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.21.1->keras-nlp) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.21.1->keras-nlp) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.21.1->keras-nlp) (25.0)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.21.1->keras-nlp) (2024.11.6)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.21.1->keras-nlp) (14.0.0)\nRequirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.21.1->keras-nlp) (0.3.12)\nRequirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.21.1->keras-nlp) (2.18.1)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.21.1->keras-nlp) (0.0.8)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.21.1->keras-nlp) (3.13.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.21.1->keras-nlp) (0.14.1)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub==0.21.1->keras-nlp) (0.4.1)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.21.1->keras-nlp) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.21.1->keras-nlp) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.21.1->keras-nlp) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->keras-hub==0.21.1->keras-nlp) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->keras-hub==0.21.1->keras-nlp) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->keras-hub==0.21.1->keras-nlp) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->keras-hub==0.21.1->keras-nlp) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->keras-hub==0.21.1->keras-nlp) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->keras-hub==0.21.1->keras-nlp) (2.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-hub==0.21.1->keras-nlp) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-hub==0.21.1->keras-nlp) (2.19.1)\nRequirement already satisfied: tensorflow<2.19,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-text->keras-hub==0.21.1->keras-nlp) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.21.1->keras-nlp) (0.1.2)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (3.4.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (4.13.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (1.72.0rc1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (2.18.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (0.37.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.21.1->keras-nlp) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.21.1->keras-nlp) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.21.1->keras-nlp) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.21.1->keras-nlp) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras-hub==0.21.1->keras-nlp) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras-hub==0.21.1->keras-nlp) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->keras-hub==0.21.1->keras-nlp) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->keras-hub==0.21.1->keras-nlp) (2024.2.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (0.45.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->keras-hub==0.21.1->keras-nlp) (2024.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.21.1->keras-nlp) (3.0.2)\nDownloading keras_nlp-0.21.1-py3-none-any.whl (1.8 kB)\nDownloading keras_hub-0.21.1-py3-none-any.whl (876 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m876.5/876.5 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: keras-hub, keras-nlp\n  Attempting uninstall: keras-hub\n    Found existing installation: keras-hub 0.18.1\n    Uninstalling keras-hub-0.18.1:\n      Successfully uninstalled keras-hub-0.18.1\n  Attempting uninstall: keras-nlp\n    Found existing installation: keras-nlp 0.18.1\n    Uninstalling keras-nlp-0.18.1:\n      Successfully uninstalled keras-nlp-0.18.1\nSuccessfully installed keras-hub-0.21.1 keras-nlp-0.21.1\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nCollecting clean-text\n  Downloading clean_text-0.6.0-py3-none-any.whl.metadata (6.6 kB)\nCollecting emoji<2.0.0,>=1.0.0 (from clean-text)\n  Downloading emoji-1.7.0.tar.gz (175 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting ftfy<7.0,>=6.0 (from clean-text)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.13)\nDownloading clean_text-0.6.0-py3-none-any.whl (11 kB)\nDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: emoji\n  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171031 sha256=579de6bca4ae746494acafdbed880e11a10448fcbd97bd1efe8306a2e0ddfa6e\n  Stored in directory: /root/.cache/pip/wheels/bd/22/e5/b69726d5e1a19795ecd3b3e7464b16c0f1d019aa94ff1c8578\nSuccessfully built emoji\nInstalling collected packages: emoji, ftfy, clean-text\n  Attempting uninstall: emoji\n    Found existing installation: emoji 2.14.1\n    Uninstalling emoji-2.14.1:\n      Successfully uninstalled emoji-2.14.1\nSuccessfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.3.1\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport keras_nlp\n\nimport pandas as pd\nfrom cleantext import clean\nimport random\n\nfrom tqdm import tqdm\nfrom tqdm._tqdm_notebook import tqdm_notebook\ntqdm_notebook.pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:39:43.213149Z","iopub.execute_input":"2025-06-05T01:39:43.213483Z","iopub.status.idle":"2025-06-05T01:39:44.197544Z","shell.execute_reply.started":"2025-06-05T01:39:43.213451Z","shell.execute_reply":"2025-06-05T01:39:44.196789Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2797471344.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n  from tqdm._tqdm_notebook import tqdm_notebook\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"BATCH_SIZE = 64\nEPOCHS = 10\nMAX_SEQUENCE_LENGTH = 150\nTEXT_VOCAB_SIZE = 7700\nSUMM_VOCAB_SIZE = 3800\n\nEMBED_DIM = 256\nINTERMEDIATE_DIM = 2048\nNUM_HEADS = 8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:39:44.198421Z","iopub.execute_input":"2025-06-05T01:39:44.198667Z","iopub.status.idle":"2025-06-05T01:39:44.202775Z","shell.execute_reply.started":"2025-06-05T01:39:44.198640Z","shell.execute_reply":"2025-06-05T01:39:44.202043Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_df = pd.read_json(\"/kaggle/input/dataset/train.json\")\ntrain_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:39:44.203731Z","iopub.execute_input":"2025-06-05T01:39:44.204060Z","iopub.status.idle":"2025-06-05T01:39:44.495058Z","shell.execute_reply.started":"2025-06-05T01:39:44.204014Z","shell.execute_reply":"2025-06-05T01:39:44.494420Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"         id                                            summary  \\\n0  13818513  Amanda baked cookies and will bring Jerry some...   \n1  13728867  Olivia and Olivier are voting for liberals in ...   \n2  13681000  Kim may try the pomodoro technique recommended...   \n3  13730747  Edward thinks he is in love with Bella. Rachel...   \n4  13728094  Sam is confused, because he overheard Rick com...   \n\n                                            dialogue  \n0  Amanda: I baked  cookies. Do you want some?\\r\\...  \n1  Olivia: Who are you voting for in this electio...  \n2  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...  \n3  Edward: Rachel, I think I'm in ove with Bella....  \n4  Sam: hey  overheard rick say something\\r\\nSam:...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>summary</th>\n      <th>dialogue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13818513</td>\n      <td>Amanda baked cookies and will bring Jerry some...</td>\n      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13728867</td>\n      <td>Olivia and Olivier are voting for liberals in ...</td>\n      <td>Olivia: Who are you voting for in this electio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13681000</td>\n      <td>Kim may try the pomodoro technique recommended...</td>\n      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13730747</td>\n      <td>Edward thinks he is in love with Bella. Rachel...</td>\n      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13728094</td>\n      <td>Sam is confused, because he overheard Rick com...</td>\n      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"print(\"Text:\\n\",train_df[\"dialogue\"][0])\nprint(\"-----------------------------\")\nprint(\"Summary: \", train_df[\"summary\"][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:39:44.495711Z","iopub.execute_input":"2025-06-05T01:39:44.495917Z","iopub.status.idle":"2025-06-05T01:39:44.500636Z","shell.execute_reply.started":"2025-06-05T01:39:44.495901Z","shell.execute_reply":"2025-06-05T01:39:44.499725Z"}},"outputs":[{"name":"stdout","text":"Text:\n Amanda: I baked  cookies. Do you want some?\nJerry: Sure!\nAmanda: I'll bring you tomorrow :-)\n-----------------------------\nSummary:  Amanda baked cookies and will bring Jerry some tomorrow.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def clean_samples(text):\n    return clean(text=text, normalize_whitespace=True, no_urls=True, no_emoji=True)\n    \ntext_pairs = []\nfor i,j in zip(train_df.dialogue, train_df.summary):\n    if len(i.split(\" \")) < MAX_SEQUENCE_LENGTH:\n        text_pairs.append((clean_samples(i),clean_samples(j)))\n# print(text_pairs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:39:44.503088Z","iopub.execute_input":"2025-06-05T01:39:44.503570Z","iopub.status.idle":"2025-06-05T01:39:50.241881Z","shell.execute_reply.started":"2025-06-05T01:39:44.503546Z","shell.execute_reply":"2025-06-05T01:39:50.241062Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def train_word_piece(text_samples, vocab_size, reserved_tokens):\n    word_piece_ds = tf.data.Dataset.from_tensor_slices(text_samples)\n    print(word_piece_ds)\n    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n    word_piece_ds.batch(1000).prefetch(2),\n    vocabulary_size=vocab_size,\n    reserved_tokens=reserved_tokens,\n    )\n    return vocab\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:39:50.242728Z","iopub.execute_input":"2025-06-05T01:39:50.242958Z","iopub.status.idle":"2025-06-05T01:39:50.247628Z","shell.execute_reply.started":"2025-06-05T01:39:50.242939Z","shell.execute_reply":"2025-06-05T01:39:50.247063Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n\ntext_samples = [text_pair[0] for text_pair in text_pairs]\n# print(text_samples)\ntext_vocab = train_word_piece(text_samples, TEXT_VOCAB_SIZE, reserved_tokens)\n\nsumm_samples = [text_pair[1] for text_pair in text_pairs]\n# print(summ_samples)\nsumm_vocab = train_word_piece(text_samples, SUMM_VOCAB_SIZE, reserved_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:39:50.248418Z","iopub.execute_input":"2025-06-05T01:39:50.249159Z","iopub.status.idle":"2025-06-05T01:40:54.296973Z","shell.execute_reply.started":"2025-06-05T01:39:50.249141Z","shell.execute_reply":"2025-06-05T01:40:54.296415Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1749087590.486314      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"print(\"Text Tokens: \", text_vocab[100:110])\nprint(\"Summarization Tokens: \", summ_vocab[100:110])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:40:54.297886Z","iopub.execute_input":"2025-06-05T01:40:54.298180Z","iopub.status.idle":"2025-06-05T01:40:54.302328Z","shell.execute_reply.started":"2025-06-05T01:40:54.298161Z","shell.execute_reply":"2025-06-05T01:40:54.301527Z"}},"outputs":[{"name":"stdout","text":"Text Tokens:  ['don', 'with', 'this', '##s', 'was', 'there', 'like', 'your', 'about', 'he']\nSummarization Tokens:  ['just', 'don', 'with', 'this', 'was', 'there', 'like', 'your', 'about', 'he']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"len(text_vocab), len(summ_vocab)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:40:54.303096Z","iopub.execute_input":"2025-06-05T01:40:54.303793Z","iopub.status.idle":"2025-06-05T01:40:54.322492Z","shell.execute_reply.started":"2025-06-05T01:40:54.303772Z","shell.execute_reply":"2025-06-05T01:40:54.321849Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(6453, 3612)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"text_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n    vocabulary=text_vocab,\n    lowercase=False)\nsumm_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\nvocabulary=summ_vocab, lowercase=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:40:54.323321Z","iopub.execute_input":"2025-06-05T01:40:54.323609Z","iopub.status.idle":"2025-06-05T01:40:54.383460Z","shell.execute_reply.started":"2025-06-05T01:40:54.323592Z","shell.execute_reply":"2025-06-05T01:40:54.382850Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"text_input_ex = text_pairs[0][0]\ntext_tokens_ex = text_tokenizer.tokenize(text_input_ex)\nprint(\"Text sentence: \",text_input_ex)\nprint(\"Tokens: \", text_tokens_ex)\nprint(\"Recovered text after detokenizing: \",text_tokenizer.detokenize(text_tokens_ex))\nprint(\"-\"*100)\nsumm_input_ex = text_pairs[0][1]\nsumm_tokens_ex = summ_tokenizer.tokenize(summ_input_ex)\nprint(\"Summarization sentence: \", summ_input_ex)\nprint(\"Tokens: \", summ_tokens_ex)\nprint(\"Recovered text after detokenizing: \",summ_tokenizer.detokenize(summ_tokens_ex))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:40:54.384162Z","iopub.execute_input":"2025-06-05T01:40:54.384382Z","iopub.status.idle":"2025-06-05T01:40:54.454506Z","shell.execute_reply.started":"2025-06-05T01:40:54.384357Z","shell.execute_reply":"2025-06-05T01:40:54.453865Z"}},"outputs":[{"name":"stdout","text":"Text sentence:  amanda: i baked cookies. do you want some?\njerry: sure!\namanda: i'll bring you tomorrow :-)\nTokens:  tf.Tensor(\n[ 410   29   49 3453 1746   17   90   70  144  123   34  572   29  115\n    4  410   29   49   10   95  303   70  172   29   16   12], shape=(26,), dtype=int32)\nRecovered text after detokenizing:  amanda : i baked cookies . do you want some ? jerry : sure ! amanda : i ' ll bring you tomorrow : - )\n----------------------------------------------------------------------------------------------------\nSummarization sentence:  amanda baked cookies and will bring jerry some tomorrow.\nTokens:  tf.Tensor([ 421 2724  164 1898   74   99  316  593  123  177   17], shape=(11,), dtype=int32)\nRecovered text after detokenizing:  amanda baked cookies and will bring jerry some tomorrow .\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def preprocess_batch(text, summ):\n    batch_size = tf.shape(summ)[0]    \n    \n    text = text_tokenizer(text)\n    print('Text1',text)\n    summ = summ_tokenizer(summ)\n    print('Summ1',summ)\n\n    text_start_end_packer = keras_nlp.layers.StartEndPacker(\n    sequence_length=MAX_SEQUENCE_LENGTH,\n    pad_value=text_tokenizer.token_to_id(\"[PAD]\"),\n    )\n    text = text_start_end_packer(text)\n    print('Text2',text)\n\n    summ_start_end_packer = keras_nlp.layers.StartEndPacker(\n    sequence_length=MAX_SEQUENCE_LENGTH + 1,\n    start_value=summ_tokenizer.token_to_id(\"[START]\"),\n    end_value=summ_tokenizer.token_to_id(\"[END]\"),\n    pad_value=summ_tokenizer.token_to_id(\"[PAD]\"),\n    )\n    summ = summ_start_end_packer(summ)\n    # en_de_dict = {\n    #     \"encoder_inputs\": text,\n    #     \"decoder_inputs\": summ[:, :-1],\n    # }\n    print('Summ2', summ)\n    \n    return (\n    {\n        \"encoder_inputs\": text,\n        \"decoder_inputs\": summ[:, :-1],\n    },\n        summ[:, 1:],\n    )\n\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:40:54.455179Z","iopub.execute_input":"2025-06-05T01:40:54.455391Z","iopub.status.idle":"2025-06-05T01:40:54.461053Z","shell.execute_reply.started":"2025-06-05T01:40:54.455375Z","shell.execute_reply":"2025-06-05T01:40:54.460439Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def make_dataset(pairs):\n    source_texts, target_texts = zip(*pairs)\n    source_texts = list(source_texts)\n    target_texts = list(target_texts)\n    dataset = tf.data.Dataset.from_tensor_slices((source_texts, target_texts))\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf.data.AUTOTUNE)\n    return dataset.shuffle(2048).prefetch(16).cache()\ntrain_ds = make_dataset(text_pairs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:40:54.461842Z","iopub.execute_input":"2025-06-05T01:40:54.462083Z","iopub.status.idle":"2025-06-05T01:40:56.160889Z","shell.execute_reply.started":"2025-06-05T01:40:54.462068Z","shell.execute_reply":"2025-06-05T01:40:56.160133Z"}},"outputs":[{"name":"stdout","text":"Text1 tf.RaggedTensor(values=Tensor(\"word_piece_tokenizer_1/FastWordpieceTokenizeWithOffsets/FastWordpieceTokenizeWithOffsets/Cast:0\", shape=(None,), dtype=int32, device=/device:CPU:*), row_splits=Tensor(\"word_piece_tokenizer_1/RaggedFromRowSplits_3/control_dependency:0\", shape=(None,), dtype=int64, device=/device:CPU:*))\nSumm1 tf.RaggedTensor(values=Tensor(\"word_piece_tokenizer_1_2/FastWordpieceTokenizeWithOffsets/FastWordpieceTokenizeWithOffsets/Cast:0\", shape=(None,), dtype=int32, device=/device:CPU:*), row_splits=Tensor(\"word_piece_tokenizer_1_2/RaggedFromRowSplits_3/control_dependency:0\", shape=(None,), dtype=int64, device=/device:CPU:*))\nText2 Tensor(\"start_end_packer_1/RaggedToTensor/RaggedTensorToTensor:0\", shape=(None, 150), dtype=int32, device=/device:CPU:*)\nSumm2 Tensor(\"start_end_packer_1_2/RaggedToTensor/RaggedTensorToTensor:0\", shape=(None, 151), dtype=int32, device=/device:CPU:*)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"for inputs, targets in train_ds.take(1):\n    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n    print(f\"targets.shape: {targets.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:40:56.161630Z","iopub.execute_input":"2025-06-05T01:40:56.161827Z","iopub.status.idle":"2025-06-05T01:40:57.009473Z","shell.execute_reply.started":"2025-06-05T01:40:56.161812Z","shell.execute_reply":"2025-06-05T01:40:57.008701Z"}},"outputs":[{"name":"stdout","text":"inputs[\"encoder_inputs\"].shape: (64, 150)\ninputs[\"decoder_inputs\"].shape: (64, 150)\ntargets.shape: (64, 150)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"\nencoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n\nembedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n    vocabulary_size=TEXT_VOCAB_SIZE,\n    sequence_length=MAX_SEQUENCE_LENGTH,\n    embedding_dim=EMBED_DIM,\n    mask_zero=True\n)\nx = embedding_layer(encoder_inputs)\n\ntransformer_encoder = keras_nlp.layers.TransformerEncoder(\nintermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS)\n\nencoder_outputs = transformer_encoder(inputs=x)\n# encoder = keras.Model(encoder_inputs, encoder_outputs)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:40:57.010431Z","iopub.execute_input":"2025-06-05T01:40:57.010709Z","iopub.status.idle":"2025-06-05T01:40:58.232400Z","shell.execute_reply.started":"2025-06-05T01:40:57.010685Z","shell.execute_reply":"2025-06-05T01:40:58.231740Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\nencoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\")\n\nx = keras_nlp.layers.TokenAndPositionEmbedding(\nvocabulary_size=SUMM_VOCAB_SIZE,\nsequence_length=MAX_SEQUENCE_LENGTH,\nembedding_dim=EMBED_DIM,\nmask_zero=True,)(decoder_inputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:40:58.233262Z","iopub.execute_input":"2025-06-05T01:40:58.233524Z","iopub.status.idle":"2025-06-05T01:40:58.249000Z","shell.execute_reply.started":"2025-06-05T01:40:58.233501Z","shell.execute_reply":"2025-06-05T01:40:58.248261Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\nencoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\")\n\nx = keras_nlp.layers.TokenAndPositionEmbedding(\nvocabulary_size=SUMM_VOCAB_SIZE,\nsequence_length=MAX_SEQUENCE_LENGTH,\nembedding_dim=EMBED_DIM,\nmask_zero=True,)(decoder_inputs)\n\ntransformer_decoder = keras_nlp.layers.TransformerDecoder(\n    intermediate_dim=INTERMEDIATE_DIM, \n    num_heads=NUM_HEADS\n)\n\nx = transformer_decoder(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n\nx = keras.layers.Dropout(0.5)(x)\ndecoder_outputs = keras.layers.Dense(SUMM_VOCAB_SIZE, activation=\"softmax\")(x)\ndecoder = keras.Model(\n[\n    decoder_inputs,\n    encoded_seq_inputs,\n],\n    decoder_outputs,\n)\n\ndecoder_outputs = decoder([decoder_inputs, encoder_outputs])\n\ntransformer = keras.Model(\n[encoder_inputs, decoder_inputs],\ndecoder_outputs,\nname=\"transformer\",)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:40:58.249835Z","iopub.execute_input":"2025-06-05T01:40:58.250160Z","iopub.status.idle":"2025-06-05T01:40:58.351294Z","shell.execute_reply.started":"2025-06-05T01:40:58.250144Z","shell.execute_reply":"2025-06-05T01:40:58.350641Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'functional' (of type Functional) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"transformer.summary()\n# encoder.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:40:58.352142Z","iopub.execute_input":"2025-06-05T01:40:58.352639Z","iopub.status.idle":"2025-06-05T01:40:58.369727Z","shell.execute_reply.started":"2025-06-05T01:40:58.352613Z","shell.execute_reply":"2025-06-05T01:40:58.369275Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"transformer\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ token_and_position_embed… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m2,009,600\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mTokenAndPositionEmbeddi…\u001b[0m │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m1,315,072\u001b[0m │ token_and_position_em… │\n│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ functional (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3800\u001b[0m)     │      \u001b[38;5;34m3,566,552\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                           │                        │                │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ token_and_position_embed… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,009,600</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbeddi…</span> │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,072</span> │ token_and_position_em… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ functional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3800</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,566,552</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                           │                        │                │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,891,224\u001b[0m (26.29 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,891,224</span> (26.29 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,891,224\u001b[0m (26.29 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,891,224</span> (26.29 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"transformer.compile(\n\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n)\ntransformer.fit(train_ds, epochs=100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T01:43:06.127462Z","iopub.execute_input":"2025-06-05T01:43:06.127964Z","iopub.status.idle":"2025-06-05T02:01:32.305819Z","shell.execute_reply.started":"2025-06-05T01:43:06.127938Z","shell.execute_reply":"2025-06-05T02:01:32.304954Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1749087797.809768     121 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 79/197\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.0641 - loss: 3.5139","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1749087807.168208     121 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 80ms/step - accuracy: 0.0653 - loss: 3.4750\nEpoch 2/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.0709 - loss: 3.2089\nEpoch 3/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.0757 - loss: 2.9937\nEpoch 4/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.0808 - loss: 2.7959\nEpoch 5/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.0844 - loss: 2.6389\nEpoch 6/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.0889 - loss: 2.4778\nEpoch 7/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.0934 - loss: 2.3204\nEpoch 8/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.0978 - loss: 2.1674\nEpoch 9/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1018 - loss: 2.0308\nEpoch 10/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1055 - loss: 1.9106\nEpoch 11/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1093 - loss: 1.7890\nEpoch 12/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1138 - loss: 1.6567\nEpoch 13/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1180 - loss: 1.5289\nEpoch 14/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1221 - loss: 1.4174\nEpoch 15/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1253 - loss: 1.3223\nEpoch 16/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1284 - loss: 1.2410\nEpoch 17/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1311 - loss: 1.1696\nEpoch 18/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1336 - loss: 1.0962\nEpoch 19/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1370 - loss: 1.0202\nEpoch 20/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1397 - loss: 0.9497\nEpoch 21/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1422 - loss: 0.8833\nEpoch 22/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1450 - loss: 0.8262\nEpoch 23/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1473 - loss: 0.7733\nEpoch 24/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1484 - loss: 0.7454\nEpoch 25/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1505 - loss: 0.6984\nEpoch 26/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1524 - loss: 0.6563\nEpoch 27/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1548 - loss: 0.6073\nEpoch 28/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1566 - loss: 0.5692\nEpoch 29/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1578 - loss: 0.5420\nEpoch 30/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1595 - loss: 0.5121\nEpoch 31/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1603 - loss: 0.4964\nEpoch 32/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1614 - loss: 0.4727\nEpoch 33/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1623 - loss: 0.4572\nEpoch 34/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1628 - loss: 0.4454\nEpoch 35/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1640 - loss: 0.4257\nEpoch 36/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1646 - loss: 0.4146\nEpoch 37/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1652 - loss: 0.4022\nEpoch 38/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1662 - loss: 0.3848\nEpoch 39/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1666 - loss: 0.3750\nEpoch 40/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1672 - loss: 0.3622\nEpoch 41/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1682 - loss: 0.3413\nEpoch 42/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1684 - loss: 0.3394\nEpoch 43/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1688 - loss: 0.3331\nEpoch 44/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1697 - loss: 0.3208\nEpoch 45/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1700 - loss: 0.3146\nEpoch 46/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1707 - loss: 0.2974\nEpoch 47/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1710 - loss: 0.2936\nEpoch 48/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1710 - loss: 0.2897\nEpoch 49/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1718 - loss: 0.2806\nEpoch 50/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1719 - loss: 0.2764\nEpoch 51/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1725 - loss: 0.2674\nEpoch 52/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1726 - loss: 0.2624\nEpoch 53/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1727 - loss: 0.2628\nEpoch 54/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1731 - loss: 0.2545\nEpoch 55/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1734 - loss: 0.2478\nEpoch 56/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1735 - loss: 0.2489\nEpoch 57/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1736 - loss: 0.2448\nEpoch 58/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1740 - loss: 0.2396\nEpoch 59/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1742 - loss: 0.2358\nEpoch 60/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1745 - loss: 0.2312\nEpoch 61/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1747 - loss: 0.2288\nEpoch 62/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1749 - loss: 0.2235\nEpoch 63/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1749 - loss: 0.2219\nEpoch 64/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1753 - loss: 0.2169\nEpoch 65/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1756 - loss: 0.2098\nEpoch 66/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1756 - loss: 0.2086\nEpoch 67/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1759 - loss: 0.2042\nEpoch 68/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1761 - loss: 0.2017\nEpoch 69/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1758 - loss: 0.2049\nEpoch 70/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1764 - loss: 0.1960\nEpoch 71/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1761 - loss: 0.2015\nEpoch 72/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1764 - loss: 0.1981\nEpoch 73/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1762 - loss: 0.1994\nEpoch 74/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1767 - loss: 0.1927\nEpoch 75/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1771 - loss: 0.1830\nEpoch 76/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1771 - loss: 0.1840\nEpoch 77/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1771 - loss: 0.1806\nEpoch 78/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1775 - loss: 0.1770\nEpoch 79/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1773 - loss: 0.1792\nEpoch 80/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1771 - loss: 0.1824\nEpoch 81/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1774 - loss: 0.1780\nEpoch 82/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1778 - loss: 0.1714\nEpoch 83/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1779 - loss: 0.1699\nEpoch 84/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1778 - loss: 0.1733\nEpoch 85/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1782 - loss: 0.1638\nEpoch 86/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1780 - loss: 0.1671\nEpoch 87/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1779 - loss: 0.1702\nEpoch 88/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1782 - loss: 0.1657\nEpoch 89/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1782 - loss: 0.1633\nEpoch 90/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1783 - loss: 0.1622\nEpoch 91/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1785 - loss: 0.1578\nEpoch 92/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1786 - loss: 0.1545\nEpoch 93/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1788 - loss: 0.1531\nEpoch 94/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1788 - loss: 0.1543\nEpoch 95/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1788 - loss: 0.1530\nEpoch 96/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1789 - loss: 0.1500\nEpoch 97/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1791 - loss: 0.1467\nEpoch 98/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1791 - loss: 0.1505\nEpoch 99/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1790 - loss: 0.1498\nEpoch 100/100\n\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1793 - loss: 0.1442\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a3d35eb7290>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"@tf.function\n\ndef decode_sequences(input_sentences):\n    batch_size = tf.shape(input_sentences)[0]\n    \n    encoder_input_tokens = text_tokenizer.tokenize(input_sentences).to_tensor(\n    shape=(None, MAX_SEQUENCE_LENGTH)\n    )\n    \n    def next(prompt, cache, index):\n        logits = transformer([encoder_input_tokens, prompt])[:, index - 1, :]\n        hidden_states = None\n        return logits, hidden_states, cache\n    \n    length = MAX_SEQUENCE_LENGTH\n    start = tf.fill((batch_size, 1), summ_tokenizer.token_to_id(\"[START]\"))\n    pad = tf.fill((batch_size, length - 1), summ_tokenizer.token_to_id(\"[PAD]\"))\n    prompt = tf.concat((start, pad), axis=-1)\n    \n    generated_tokens = keras_nlp.samplers.GreedySampler()(\n    next,\n    prompt,\n    index=1, \n    )\n    generated_sentences = summ_tokenizer.detokenize(generated_tokens)\n    return generated_sentences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T02:01:32.307359Z","iopub.execute_input":"2025-06-05T02:01:32.307581Z","iopub.status.idle":"2025-06-05T02:01:32.320394Z","shell.execute_reply.started":"2025-06-05T02:01:32.307565Z","shell.execute_reply":"2025-06-05T02:01:32.319593Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def truncate_at_end(text):\n    if \"[END]\" in text:\n        end_position = text.find(\"[END]\")\n        return text[:end_position].strip()\n    return text.strip()\n\nfor i in range(4):\n    choice = random.randint(0, len(test_texts))\n    input_sentence = test_texts[choice]\n    summarized = decode_sequences(tf.constant([input_sentence]))\n    summarized = summarized.numpy()[0].decode(\"utf-8\")\n    \n    summarized = truncate_at_end(summarized)\n    \n    summarized = (\n        summarized.replace(\"[PAD]\", \"\")\n        .replace(\"[START]\", \"\")\n        .replace(\"[END]\", \"\")  \n        .strip()\n    )\n    print(f\"** Example {i} **\")\n    print(\"Text:\", input_sentence)\n    print(\"Prediction:\", summarized)\n    print(\"Ground Truth:\", original[choice])\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T02:12:20.200882Z","iopub.execute_input":"2025-06-05T02:12:20.201608Z","iopub.status.idle":"2025-06-05T02:12:21.770994Z","shell.execute_reply.started":"2025-06-05T02:12:20.201587Z","shell.execute_reply":"2025-06-05T02:12:21.770375Z"}},"outputs":[{"name":"stdout","text":"** Example 0 **\nText: tom: hey, you forgot your scarf yesterday\ntom: so you have an excuse to drop by :d\njim: haha. sure. i'll handle myself without a scarf until tomorrow.\njim: i'll visit you \"to get my scarf\" after work if you know what i mean :d\ntom: hahaha. sure. see you then.\nPrediction: jim has forgot his scarf yesterday . he ' ll visit tom tomorrow .\nGround Truth: jim has forgot his scarf yesterday. he'll visit tom tomorrow after work to get it.\n\n** Example 1 **\nText: aretha: i've put some plants on your terrace this morning. in the shade. all perennials.\nlucia: thanks a lot! you don't want them any more?\naretha: they're from dorothea. i just have no more space. happy planting!\nlucia: ta!\nPrediction: aretha has put some plants from dorothea on lucia ' s terrace this morning .\nGround Truth: aretha has put some plants from dorothea on lucia's terrace this morning.\n\n** Example 2 **\nText: ellen: let's go shopping tomorrow\nportia: nooooo, it's too close to christmas\nellen: we could make a day out if eat, have lunch at the food court, i know you love junk food :d\nportia: i do love junk food. but not as much as i hate christmas crowds\nellen: you grinch\nportia: :p i higly recommend: <url>\nellen: <file_gif>\nPrediction: ellen would like to go shopping with portia tomorrow , but she refuses for fear of christmas crowds .\nGround Truth: ellen would like to go shopping with portia tomorrow, but she refuses for fear of christmas crowds.\n\n** Example 3 **\nText: walter: have you bought dad a christmas gift yet?\nsusan: no. have you?\nwalter: no, not yet.\nsusan: what are you thinking of getting him?\nwalter: a new razor, maybe. and you?\nsusan: the same.\nwalter: oh. well, i can get him a cd i guess. it's more interesting than the winter socks he always asks for.\nsusan: whatever you want to do. i may not end up getting him a razor after all.\nPrediction: walter wants to buy a new razor for their dad for christmas . he will buy a cd as susan wants to buy the same . susan may change her mind about the gift .\nGround Truth: walter and susan haven't bought dad a christmas gift yet. they're thinking of giving him a razor or a cd.\n\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}